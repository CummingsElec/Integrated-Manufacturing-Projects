<div align="center">

<img src="../../Asthetics/Cerberus.png" alt="CERBERUS Banner" width="100%"/>

# CERBERUS

**Cummings Electrical Robotic Breaker & Equipment Recognition Unified System**

> Automated robotic system for documenting electrical panels using computer vision and multi-model AI

[![Status](https://img.shields.io/badge/Status-Active_Development-blue?style=flat-square)](#)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=flat-square&logo=python&logoColor=white)](#)
[![YOLO](https://img.shields.io/badge/YOLO-v8-00FFFF?style=flat-square)](#)
[![Robotics](https://img.shields.io/badge/Robotics-6--DOF-9C27B0?style=flat-square)](#)

</div>

---

## Problem Statement

Documenting electrical panels during service calls or new installations is time-consuming, error-prone, and requires trained technicians to manually identify and record breaker information. This process can take hours for large commercial panels with dozens of breakers.

**CERBERUS automates this workflow** by combining robotic positioning, high-resolution imaging, and AI-powered recognition to capture complete panel documentation in minutes.

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CERBERUS System                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Robot Arm  â”‚    â”‚    Gantry    â”‚    â”‚   Cameras    â”‚      â”‚
â”‚  â”‚   (6-DOF)    â”‚â—„â”€â”€â–ºâ”‚   (Linear)   â”‚â—„â”€â”€â–ºâ”‚  (Hi-Res)    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                  â”‚                   â”‚               â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                             â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                    â”‚  Vision AI   â”‚                             â”‚
â”‚                    â”‚ (YOLO + OCR) â”‚                             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                             â”‚                                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚          â–¼                  â–¼                  â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Local LLM   â”‚  â”‚   Cloud AI   â”‚  â”‚    Backup    â”‚         â”‚
â”‚  â”‚  (Primary)   â”‚  â”‚  (Fallback)  â”‚  â”‚   Provider   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The system operates in three stages:
1. **Capture** â€” Robotic arm positions camera across panel surface via linear gantry
2. **Detect** â€” YOLO models identify panels, breakers, and text regions
3. **Recognize** â€” OCR extracts part numbers, validated by multi-model AI pipeline

---

## Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **ML Framework** | PyTorch + Ultralytics | YOLO model training and inference |
| **Object Detection** | YOLOv8 (custom trained) | Panel and breaker localization |
| **OCR** | PaddleOCR | Text extraction from breaker labels |
| **Robot Control** | LeRobot (HuggingFace) | 6-DOF arm motion planning |
| **Edge Processing** | Raspberry Pi | On-site capture and preprocessing |
| **PLC** | Arduino-compatible | Gantry motor control |
| **AI Backend** | Local LLM + Cloud APIs | Part number validation |

---

## Core Features

### ğŸ¤– Robotic Capture System
- **6-DOF robotic arm** for precise camera positioning
- **Linear gantry** (650mm stroke) for horizontal panel scanning
- **Multi-waypoint motion paths** with safety interlocks
- **Automatic torque management** and emergency stop capability

### ğŸ¯ Computer Vision Pipeline
- **Custom YOLO models** trained for 15+ detection classes
- **Polygon annotation tool** for training data creation
- **Local CUDA training** with automatic GPU optimization
- **Google Colab integration** for cloud-based training

### ğŸ” AI-Powered Recognition
- **Multi-model inference** with local-first, cloud-fallback strategy
- **OCR confidence scoring** for reliable text extraction
- **Part number validation** against known breaker databases
- **Phase detection** for multi-pole breakers

### ğŸ“¡ Edge Deployment
- **Raspberry Pi integration** for portable on-site use
- **Cloud synchronization** for centralized data storage
- **Offline capability** with local inference

---

## Detection Classes

The YOLO model is trained to recognize:

| Category | Classes |
|----------|---------|
| **Structural** | Panel boundary, panel label |
| **Components** | Breaker face, text region |
| **Manufacturers** | Various breaker types (ELB, LS, Schneider, etc.) |

---

## Project Structure

```
cerberus/
â”œâ”€â”€ yolo_training/           # Model training pipeline
â”‚   â”œâ”€â”€ configs/             # Training configurations
â”‚   â”œâ”€â”€ tools/               # Annotation utilities
â”‚   â””â”€â”€ colab/               # Cloud training notebooks
â”œâ”€â”€ robot_control/           # Robotic arm framework
â”œâ”€â”€ vision_model/            # Inference and runtime
â”œâ”€â”€ services/                # Background daemons
â”œâ”€â”€ edge_pipeline/           # Raspberry Pi components
â”œâ”€â”€ plc_firmware/            # Gantry controller code
â””â”€â”€ tools/                   # Diagnostics & utilities
```

---

## Current Status

**ğŸ”„ Active Development**

- âœ… Robotic arm integration complete
- âœ… Custom YOLO training pipeline operational
- âœ… Multi-model AI inference working
- ğŸ”„ Edge deployment optimization in progress
- ğŸ“‹ Production packaging planned


## Business Value

| Metric | Before | After |
|--------|--------|-------|
| **Panel documentation time** | 2-4 hours | 15-30 minutes |
| **Data entry errors** | 5-10% | <1% |
| **Technician skill required** | Senior | Any trained operator |
| **Documentation completeness** | Variable | 100% captured |

---

## Acknowledgments

- [LeRobot](https://github.com/huggingface/lerobot) by HuggingFace â€” Robot control framework
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) â€” Object detection
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) â€” Text recognition

---

<div align="center">

**Robotic Automation â€¢ Computer Vision â€¢ Edge AI**

</div>

